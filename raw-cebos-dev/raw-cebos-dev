import boto3
import codecs
import sys
import datetime
import json
from pyspark.sql.functions import *
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from awsglue.dynamicframe import DynamicFrame
from pyspark.context import SparkContext, SparkConf
from awsglue.context import GlueContext
from awsglue.job import Job
from pyspark.sql import SQLContext
from boto3.dynamodb.conditions import Key, Attr
import time
import pytz
import re

sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session

## @params: [JOB_NAME]
args = getResolvedOptions(sys.argv, ['JOB_NAME'])
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

job_name = args['JOB_NAME']

glueContext = GlueContext(SparkContext.getOrCreate())
spark_session = glueContext.spark_session
sqlContext = SQLContext(spark_session.sparkContext, spark_session)

#Fun to insert data into DynamoDB log table
def put_data(logid, job_name, source_system, table_name, start_time):
    dynamodb = boto3.resource('dynamodb')
    control_table = dynamodb.Table('DataLogMaster')
    response = control_table.put_item(
        Item={
            'logid': logid,
            'job_name' : job_name,
            'source_system' : source_system,
            'table_name' : table_name,
            'start_time' : start_time
            }
        )
    return response

#Fun to update DynamoDB log table data
def update_data(logid, end_time, row_count):
    dynamodb = boto3.resource('dynamodb')
    devices_table = dynamodb.Table('DataLogMaster')
    response = devices_table.update_item(
        Key={
            'logid': logid
        },
        UpdateExpression="set end_time= :e, row_count= :r",
        ExpressionAttributeValues={
            ':e': end_time,
            ':r': row_count
        },
        ReturnValues="UPDATED_NEW"
    )
    return response

#Fun to read data from DynamoDB control table
def scan_table(SourceSystem,IsActive,RestartabilityFlag):
    
    dynamodb_client = boto3.resource('dynamodb')
    table = dynamodb_client.Table('ControlTable')

    if SourceSystem:
        filtering_exp = Key('SourceSystem').eq(SourceSystem) & Key('IsActive').eq(IsActive) & Key('RestartabilityFlag').eq(RestartabilityFlag)
        response = table.scan(FilterExpression=filtering_exp)
    else:
        response = table.scan()
    items = response['Items']
    return items

#Fun to update DynamoDB table data
def update_RestartabilityFlag(SchemaName, TableName, RestartabilityFlag):
    dynamodb = boto3.resource('dynamodb')
    devices_table = dynamodb.Table('ControlTable')
    response = devices_table.update_item(
        Key={
            'SchemaName': SchemaName,
            'TableName': TableName
        },
        UpdateExpression="set RestartabilityFlag= :r",
        ExpressionAttributeValues={
            ':r': RestartabilityFlag
        },
        ReturnValues="UPDATED_NEW"
    )
    return response


#Fun to read data from DynamoDB table to check load date
def scan_logtable(job_name, date):
    
    dynamodb_client = boto3.resource('dynamodb')
    table = dynamodb_client.Table('Dev-GlueJobs-LoggingTable')

    if date:
        filtering_exp = Attr('jobName').eq(job_name) & Key('time').begins_with(date)
        response = table.scan(FilterExpression=filtering_exp)
    else:
        response = table.scan()
    items = response['Items']
    return items

# Getting DB credentials from Secrets Manager
client = boto3.client("secretsmanager", region_name="us-east-1")

get_secret_value_response = client.get_secret_value(SecretId="glue/test/cebos/eqmsrt")

secret = get_secret_value_response['SecretString']
secret = json.loads(secret)

db_username = secret.get('db_username')
db_password = secret.get('db_password')
est = pytz.timezone('US/Eastern')
    
    
date = datetime.datetime.now().strftime('%Y-%m-%d')

if len(scan_table('CEBOS',1,0)) == 0 or len(scan_logtable(job_name, date)) == 0:
    
    table_items = scan_table('CEBOS',1,1)
    
    for dict1 in table_items:
        
        Library_Name = dict1["SchemaName"]
        Table_name = dict1["TableName"]
        
        update_response = update_RestartabilityFlag(Library_Name, Table_name, 0)

table_items = scan_table('CEBOS',1,0)

for dict1 in table_items:
    
    Library_Name = dict1["SchemaName"]
    Table_name = dict1["TableName"]
    s3_path = dict1["S3Path"]
    Flag = dict1["IsActive"]
    
    if int(Flag) == 1:
        
        print(Table_name)
        
        current_date = datetime.datetime.now().astimezone(est)
        
        logid = Table_name + ' - ' + str(current_date.year*10000000000 + current_date.month * 100000000 + current_date.day * 1000000 + current_date.hour*10000 + current_date.minute*100 + current_date.second)
        
        resp = put_data(logid, job_name, 'cebos', Table_name, str(current_date))
        
        s3_output = s3_path + str(Library_Name) + "/" + str(Table_name)
        
        df = glueContext.read.format("jdbc").option("driver", "com.microsoft.sqlserver.jdbc.SQLServerDriver").option("url", "jdbc:sqlserver://172.16.123.17:1433;databaseName=master").option("dbtable", "EQMSRT." + Library_Name + "." + Table_name).option("user", db_username).option("password", db_password).load()
        df = df.withColumn('DataLoadDateTimeRaw', lit(current_date))
        datasource0 = DynamicFrame.fromDF(df, glueContext, "datasource0")
        
        resolvechoice2 = ResolveChoice.apply(frame = datasource0, choice = "make_struct", transformation_ctx = "resolvechoice2")
        dropnullfields3 = DropNullFields.apply(frame = resolvechoice2, transformation_ctx = "dropnullfields3")
        
        final_df = dropnullfields3.toDF()
        
        row_count = final_df.count()
        
        # datasink4 = glueContext.write_dynamic_frame.from_options(frame = dropnullfields3, connection_type = "s3", connection_options = {"path": s3_output}, format = "parquet", transformation_ctx = "datasink4")
        
        final_df.write.mode("overwrite").format("parquet").save(s3_output)
        
        update_response = update_data(logid, str(datetime.datetime.now()), row_count)
        
        update_response = update_RestartabilityFlag(Library_Name, Table_name, 1)
        print("adding a print statement")
    
job.commit()
